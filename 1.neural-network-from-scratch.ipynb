{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tejasurya/neural-network-from-scratch?scriptVersionId=229873843\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"bddc23e8","metadata":{"papermill":{"duration":0.002312,"end_time":"2025-03-26T18:57:09.214634","exception":false,"start_time":"2025-03-26T18:57:09.212322","status":"completed"},"tags":[]},"source":["# Neural network from scratch with Numpy"]},{"cell_type":"code","execution_count":1,"id":"a031944c","metadata":{"execution":{"iopub.execute_input":"2025-03-26T18:57:09.219409Z","iopub.status.busy":"2025-03-26T18:57:09.21913Z","iopub.status.idle":"2025-03-26T18:57:10.39912Z","shell.execute_reply":"2025-03-26T18:57:10.398435Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":1.183997,"end_time":"2025-03-26T18:57:10.400641","exception":false,"start_time":"2025-03-26T18:57:09.216644","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import scipy  as scp\n","from scipy import optimize"]},{"cell_type":"code","execution_count":2,"id":"d11f3620","metadata":{"execution":{"iopub.execute_input":"2025-03-26T18:57:10.405337Z","iopub.status.busy":"2025-03-26T18:57:10.405016Z","iopub.status.idle":"2025-03-26T18:57:10.416552Z","shell.execute_reply":"2025-03-26T18:57:10.415831Z"},"papermill":{"duration":0.014977,"end_time":"2025-03-26T18:57:10.417634","exception":false,"start_time":"2025-03-26T18:57:10.402657","status":"completed"},"tags":[]},"outputs":[],"source":["class neural_network(object):\n","    def __init__(self,Lambda):\n","        #Initialize all hyperparameters\n","        self.inputLayerSize=2\n","        self.hiddenLayerSize=3\n","        self.outputLayerSize=1\n","\n","        # Initialize weights \n","        self.w_1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n","        self.w_2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n","        \n","        #initialize biases\n","        self.b_1 = np.random.uniform(self.hiddenLayerSize)\n","        self.b_2 = np.random.uniform(self.outputLayerSize)\n","\n","        self.Lambda = Lambda\n","\n","    def sigmoid(self,z):\n","        # Sigmoid activation function\n","        return 1/(1+np.exp(-z))\n","    \n","    def sigmoid_diff(self,z):\n","        # Gradient of Sigmoid function\n","        return np.exp(-z)/((1+np.exp(-z))**2)\n","    \n","    def softmax(self,z):\n","        #Softmax activation function\n","        return z/np.sum(z,axis=0)\n","\n","    def relu(self,z):\n","        # ReLu activation function\n","        relu = list()\n","        for row in z:\n","            rr=[]\n","            for col in row:\n","                if col<=0:\n","                    rr.append(0)\n","                else:\n","                    rr.append(col)\n","            relu.append(rr)\n","        relu=np.array(relu)    \n","        return relu\n","    \n","    def relu__diff(self,z):\n","        # ReLu gradient activation function\n","        self.relu_diff = list()\n","        for row in z:\n","            rr=[]\n","            for col in row:\n","                if col<=0:\n","                    rr.append(0)\n","                else:\n","                    rr.append(1)\n","            self.relu_diff.append(rr)\n","        self.relu_diff=np.array(relu)    \n","        return self.relu_diff\n","\n","    def forward_nn(self,X):\n","        # Forward pass of the neural network\n","        self.z_2 = np.dot(X,self.w_1) #+ self.b_1\n","        self.a_2 = self.sigmoid(self.z_2)\n","        self.z_3 = np.dot(self.a_2,self.w_2) #+ self.b_2\n","        y_hat = self.sigmoid(self.z_3)\n","        \n","        return y_hat\n","    \n","    def cost_function(self,X,y):\n","        # Computing the cost of the given X and y\n","        self.y_hat = self.forward_nn(X)\n","        J = sum((y-self.y_hat)**2)/X.shape[0] #\\\n","                # + (self.Lambda/2)*(sum(self.w_1**2+self.w_2**2))\n","        \n","        return J\n","    \n","    def cost_function_diff(self,X,y):\n","        # compute the derivative w.r.t. w and w1 for a given X and y\n","        self.y_hat = self.forward_nn(X)\n","\n","        delta3  = np.multiply(-(y-self.y_hat),self.sigmoid_diff(self.z_3))\n","        dJdW2 = np.dot(self.a_2.T, delta3)/X.shape[0] #+ self.Lambda*self.w_2\n","\n","        delta2 = np.dot(delta3,self.w_2.T)*self.sigmoid_diff(self.z_2)        \n","        dJdW1 = np.dot(X.T,delta2)/X.shape[0] #+ self.Lambda*self.w_1\n","\n","        # print(dJdW1,dJdW2)\n","        return dJdW1,dJdW2\n","\n","    def backward_nn(self,X,y):\n","        # Compute the Gradients\n","        dJdW1 , dJdW2 = self.cost_function_diff(X,y)\n","        return np.concatenate((dJdW1.ravel(),dJdW2.ravel()))\n","    \n","    # Helper functions - get/set functions\n","    def getParams(self):\n","        # Get W1 and W2 using single parameter vector\n","        params = np.concatenate((self.w_1.ravel(),self.w_2.ravel()))\n","        return params\n","    \n","    def setParams(self, params):\n","        # Set W1 and W2 using single parameter vector\n","        W1_start = 0\n","        W1_end = self.hiddenLayerSize*self.inputLayerSize\n","        \n","        self.w_1 = np.reshape(params[W1_start:W1_end],(self.inputLayerSize,self.hiddenLayerSize))\n","        W2_end = W1_end + self.hiddenLayerSize*self.inputLayerSize\n","        self.w_2 = np.reshape(params[W1_end:W2_end],(self.hiddenLayerSize,self.outputLayerSize))\n","\n"]},{"cell_type":"code","execution_count":3,"id":"e6c8f718","metadata":{"execution":{"iopub.execute_input":"2025-03-26T18:57:10.421644Z","iopub.status.busy":"2025-03-26T18:57:10.421418Z","iopub.status.idle":"2025-03-26T18:57:10.427038Z","shell.execute_reply":"2025-03-26T18:57:10.426263Z"},"papermill":{"duration":0.008951,"end_time":"2025-03-26T18:57:10.428294","exception":false,"start_time":"2025-03-26T18:57:10.419343","status":"completed"},"tags":[]},"outputs":[],"source":["# training Class\n","class trainer(object):\n","    def __init__(self,nn):\n","        # Make reference to the Neural Network\n","        self.N = nn \n","    \n","    def callbacks(self,params):\n","        self.N.setParams(params)\n","        self.J.append(self.N.cost_function(self.X, self.y))\n","        self.J.append(self.N.cost_function(self.testX, self.testY))\n","    \n","    def costFunctionWrapper(self, params, X, y):\n","        self.N.setParams(params)\n","        cost = self.N.cost_function(X,y)\n","        gradient = self.N.backward_nn(X,y)\n","        #print(cost,gradient)\n","        return cost , gradient\n","    \n","    def train(self,trainX,trainY, testX, testY):\n","        # Make an internal variable for the callback function\n","        self.X = trainX\n","        self.y = trainY\n","\n","        self.testX = testX\n","        self.testY = testY\n","\n","        # Empty lists to store costs\n","        self.J = []\n","        self.testJ =[]\n","\n","        params_0 = self.N.getParams()\n","\n","        options = {'maxiter': 300, 'disp': True}\n","\n","        _res = optimize.minimize(self.costFunctionWrapper, params_0, jac = True, \\\n","                                 method = 'BFGS', args=(trainX,trainY), options = options, \\\n","                                 callback=self.callbacks)\n","        \n","        self.N.setParams(_res.x)\n","        self.optimizationResults = _res\n","\n"]},{"cell_type":"markdown","id":"85bd2f3d","metadata":{"papermill":{"duration":0.001448,"end_time":"2025-03-26T18:57:10.431444","exception":false,"start_time":"2025-03-26T18:57:10.429996","status":"completed"},"tags":[]},"source":["Problem is a **Regression problem** with 2 independent features in the training dataset,1 target feature. "]},{"cell_type":"code","execution_count":4,"id":"2a7f6510","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2025-03-26T18:57:10.435382Z","iopub.status.busy":"2025-03-26T18:57:10.435164Z","iopub.status.idle":"2025-03-26T18:57:10.488908Z","shell.execute_reply":"2025-03-26T18:57:10.488108Z"},"papermill":{"duration":0.057011,"end_time":"2025-03-26T18:57:10.490102","exception":false,"start_time":"2025-03-26T18:57:10.433091","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Training X:\n"," [[ 4.  7.]\n"," [ 6.  2.]\n"," [10.  5.]]\n","Optimization terminated successfully.\n","         Current function value: 0.000000\n","         Iterations: 71\n","         Function evaluations: 78\n","         Gradient evaluations: 78\n","Train input:\n"," [[0.4        1.        ]\n"," [0.6        0.28571429]\n"," [1.         0.71428571]]\n","Expected training output y:\n"," [[0.51]\n"," [0.76]\n"," [0.89]]\n","predicted Train output:\n"," [[0.51000626]\n"," [0.76000373]\n"," [0.88998527]]\n","TEST input:\n"," [[0.4        1.        ]\n"," [0.3        0.18181818]\n"," [1.         0.54545455]]\n","Expected output y:\n"," [[70.]\n"," [45.]\n"," [85.]]\n","predicted output:\n"," [[0.51000626]\n"," [0.56142562]\n"," [0.87766072]]\n"]}],"source":["Lambda = 0.0001\n","if __name__ == '__main__':\n","    NN = neural_network(Lambda=Lambda)\n","    # X are independant variables, y is dependant features\n","    # This problem is a Regression problem\n","    trainX = np.array(([[4,7],[6,2],[10,5]]), dtype=float)\n","    trainy = np.array(([51],[76],[89]), dtype=float)\n","\n","    #trainX = np.random.randint(low=1,high=12,size=(10000,2))\n","    #trainy = np.random.randint(low=50,high=100,size=(10000,1))\n","\n","    print(\"Training X:\\n\",trainX)\n","\n","    testX = np.array(([[4,5.5],[3,1],[10,3]]), dtype=float)\n","    testy = np.array(([70],[45],[85]), dtype=float)\n","\n","    trainX = trainX/np.max(trainX,axis=0)\n","    \n","    trainy = trainy/100\n","    \n","    testX = testX/np.max(testX,axis=0)\n","    testY = testy/100\n","\n","    T = trainer(NN)\n","    T.train(trainX,trainy,testX,testy)\n","\n","    print(\"Train input:\\n\",trainX)\n","    print(\"Expected training output y:\\n\", trainy)\n","    \n","    y_hat=NN.forward_nn(trainX)\n","    print(\"predicted Train output:\\n\",y_hat)\n","\n","    print(\"TEST input:\\n\",testX)\n","    print(\"Expected output y:\\n\", testy)\n","    \n","    y_hat=NN.forward_nn(testX)\n","    print(\"predicted output:\\n\",y_hat)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":4.249275,"end_time":"2025-03-26T18:57:10.909095","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-26T18:57:06.65982","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}