{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b7018c",
   "metadata": {
    "papermill": {
     "duration": 0.002164,
     "end_time": "2025-03-26T18:48:46.255044",
     "exception": false,
     "start_time": "2025-03-26T18:48:46.252880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Neural network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bfc68ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:48:46.259801Z",
     "iopub.status.busy": "2025-03-26T18:48:46.259447Z",
     "iopub.status.idle": "2025-03-26T18:48:47.516317Z",
     "shell.execute_reply": "2025-03-26T18:48:47.515648Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 1.26099,
     "end_time": "2025-03-26T18:48:47.517887",
     "exception": false,
     "start_time": "2025-03-26T18:48:46.256897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy  as scp\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7a9478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:48:47.522460Z",
     "iopub.status.busy": "2025-03-26T18:48:47.522141Z",
     "iopub.status.idle": "2025-03-26T18:48:47.533955Z",
     "shell.execute_reply": "2025-03-26T18:48:47.533150Z"
    },
    "papermill": {
     "duration": 0.015448,
     "end_time": "2025-03-26T18:48:47.535256",
     "exception": false,
     "start_time": "2025-03-26T18:48:47.519808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class neural_network(object):\n",
    "    def __init__(self,Lambda):\n",
    "        #Initialize all hyperparameters\n",
    "        self.inputLayerSize=2\n",
    "        self.hiddenLayerSize=3\n",
    "        self.outputLayerSize=1\n",
    "\n",
    "        # Initialize weights \n",
    "        self.w_1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.w_2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        \n",
    "        #initialize biases\n",
    "        self.b_1 = np.random.uniform(self.hiddenLayerSize)\n",
    "        self.b_2 = np.random.uniform(self.outputLayerSize)\n",
    "\n",
    "        self.Lambda = Lambda\n",
    "\n",
    "    def sigmoid(self,z):\n",
    "        # Sigmoid activation function\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoid_diff(self,z):\n",
    "        # Gradient of Sigmoid function\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def softmax(self,z):\n",
    "        #Softmax activation function\n",
    "        return z/np.sum(z,axis=0)\n",
    "\n",
    "    def relu(self,z):\n",
    "        # ReLu activation function\n",
    "        relu = list()\n",
    "        for row in z:\n",
    "            rr=[]\n",
    "            for col in row:\n",
    "                if col<=0:\n",
    "                    rr.append(0)\n",
    "                else:\n",
    "                    rr.append(col)\n",
    "            relu.append(rr)\n",
    "        relu=np.array(relu)    \n",
    "        return relu\n",
    "    \n",
    "    def relu__diff(self,z):\n",
    "        # ReLu gradient activation function\n",
    "        self.relu_diff = list()\n",
    "        for row in z:\n",
    "            rr=[]\n",
    "            for col in row:\n",
    "                if col<=0:\n",
    "                    rr.append(0)\n",
    "                else:\n",
    "                    rr.append(1)\n",
    "            self.relu_diff.append(rr)\n",
    "        self.relu_diff=np.array(relu)    \n",
    "        return self.relu_diff\n",
    "\n",
    "    def forward_nn(self,X):\n",
    "        # Forward pass of the neural network\n",
    "        self.z_2 = np.dot(X,self.w_1) #+ self.b_1\n",
    "        self.a_2 = self.sigmoid(self.z_2)\n",
    "        self.z_3 = np.dot(self.a_2,self.w_2) #+ self.b_2\n",
    "        y_hat = self.sigmoid(self.z_3)\n",
    "        \n",
    "        return y_hat\n",
    "    \n",
    "    def cost_function(self,X,y):\n",
    "        # Computing the cost of the given X and y\n",
    "        self.y_hat = self.forward_nn(X)\n",
    "        J = sum((y-self.y_hat)**2)/X.shape[0] #\\\n",
    "                # + (self.Lambda/2)*(sum(self.w_1**2+self.w_2**2))\n",
    "        \n",
    "        return J\n",
    "    \n",
    "    def cost_function_diff(self,X,y):\n",
    "        # compute the derivative w.r.t. w and w1 for a given X and y\n",
    "        self.y_hat = self.forward_nn(X)\n",
    "\n",
    "        delta3  = np.multiply(-(y-self.y_hat),self.sigmoid_diff(self.z_3))\n",
    "        dJdW2 = np.dot(self.a_2.T, delta3)/X.shape[0] #+ self.Lambda*self.w_2\n",
    "\n",
    "        delta2 = np.dot(delta3,self.w_2.T)*self.sigmoid_diff(self.z_2)        \n",
    "        dJdW1 = np.dot(X.T,delta2)/X.shape[0] #+ self.Lambda*self.w_1\n",
    "\n",
    "        # print(dJdW1,dJdW2)\n",
    "        return dJdW1,dJdW2\n",
    "\n",
    "    def backward_nn(self,X,y):\n",
    "        # Compute the Gradients\n",
    "        dJdW1 , dJdW2 = self.cost_function_diff(X,y)\n",
    "        return np.concatenate((dJdW1.ravel(),dJdW2.ravel()))\n",
    "    \n",
    "    # Helper functions - get/set functions\n",
    "    def getParams(self):\n",
    "        # Get W1 and W2 using single parameter vector\n",
    "        params = np.concatenate((self.w_1.ravel(),self.w_2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        # Set W1 and W2 using single parameter vector\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize*self.inputLayerSize\n",
    "        \n",
    "        self.w_1 = np.reshape(params[W1_start:W1_end],(self.inputLayerSize,self.hiddenLayerSize))\n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.inputLayerSize\n",
    "        self.w_2 = np.reshape(params[W1_end:W2_end],(self.hiddenLayerSize,self.outputLayerSize))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5813a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:48:47.539319Z",
     "iopub.status.busy": "2025-03-26T18:48:47.539117Z",
     "iopub.status.idle": "2025-03-26T18:48:47.544543Z",
     "shell.execute_reply": "2025-03-26T18:48:47.543907Z"
    },
    "papermill": {
     "duration": 0.008724,
     "end_time": "2025-03-26T18:48:47.545709",
     "exception": false,
     "start_time": "2025-03-26T18:48:47.536985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training Class\n",
    "class trainer(object):\n",
    "    def __init__(self,nn):\n",
    "        # Make reference to the Neural Network\n",
    "        self.N = nn \n",
    "    \n",
    "    def callbacks(self,params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.cost_function(self.X, self.y))\n",
    "        self.J.append(self.N.cost_function(self.testX, self.testY))\n",
    "    \n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.cost_function(X,y)\n",
    "        gradient = self.N.backward_nn(X,y)\n",
    "        #print(cost,gradient)\n",
    "        return cost , gradient\n",
    "    \n",
    "    def train(self,trainX,trainY, testX, testY):\n",
    "        # Make an internal variable for the callback function\n",
    "        self.X = trainX\n",
    "        self.y = trainY\n",
    "\n",
    "        self.testX = testX\n",
    "        self.testY = testY\n",
    "\n",
    "        # Empty lists to store costs\n",
    "        self.J = []\n",
    "        self.testJ =[]\n",
    "\n",
    "        params_0 = self.N.getParams()\n",
    "\n",
    "        options = {'maxiter': 300, 'disp': True}\n",
    "\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params_0, jac = True, \\\n",
    "                                 method = 'BFGS', args=(trainX,trainY), options = options, \\\n",
    "                                 callback=self.callbacks)\n",
    "        \n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a3db1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:48:47.549719Z",
     "iopub.status.busy": "2025-03-26T18:48:47.549439Z",
     "iopub.status.idle": "2025-03-26T18:48:47.595963Z",
     "shell.execute_reply": "2025-03-26T18:48:47.595236Z"
    },
    "papermill": {
     "duration": 0.050197,
     "end_time": "2025-03-26T18:48:47.597577",
     "exception": false,
     "start_time": "2025-03-26T18:48:47.547380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X:\n",
      " [[ 4.  7.]\n",
      " [ 6.  2.]\n",
      " [10.  5.]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000033\n",
      "         Iterations: 37\n",
      "         Function evaluations: 40\n",
      "         Gradient evaluations: 40\n",
      "Train input:\n",
      " [[0.4        1.        ]\n",
      " [0.6        0.28571429]\n",
      " [1.         0.71428571]]\n",
      "Expected training output y:\n",
      " [[0.51]\n",
      " [0.76]\n",
      " [0.89]]\n",
      "predicted Train output:\n",
      " [[0.50000001]\n",
      " [0.75996061]\n",
      " [0.88991619]]\n",
      "TEST input:\n",
      " [[0.4        1.        ]\n",
      " [0.3        0.18181818]\n",
      " [1.         0.54545455]]\n",
      "Expected output y:\n",
      " [[70.]\n",
      " [45.]\n",
      " [85.]]\n",
      "predicted output:\n",
      " [[0.50000001]\n",
      " [0.81797441]\n",
      " [0.75918426]]\n"
     ]
    }
   ],
   "source": [
    "Lambda = 0.0001\n",
    "if __name__ == '__main__':\n",
    "    NN = neural_network(Lambda=Lambda)\n",
    "    trainX = np.array(([[4,7],[6,2],[10,5]]), dtype=float)\n",
    "    trainy = np.array(([51],[76],[89]), dtype=float)\n",
    "\n",
    "    #trainX = np.random.randint(low=1,high=12,size=(10000,2))\n",
    "    #trainy = np.random.randint(low=50,high=100,size=(10000,1))\n",
    "\n",
    "    print(\"Training X:\\n\",trainX)\n",
    "\n",
    "    testX = np.array(([[4,5.5],[3,1],[10,3]]), dtype=float)\n",
    "    testy = np.array(([70],[45],[85]), dtype=float)\n",
    "\n",
    "    trainX = trainX/np.max(trainX,axis=0)\n",
    "    \n",
    "    trainy = trainy/100\n",
    "    \n",
    "    testX = testX/np.max(testX,axis=0)\n",
    "    testY = testy/100\n",
    "\n",
    "    T = trainer(NN)\n",
    "    T.train(trainX,trainy,testX,testy)\n",
    "\n",
    "    print(\"Train input:\\n\",trainX)\n",
    "    print(\"Expected training output y:\\n\", trainy)\n",
    "    \n",
    "    y_hat=NN.forward_nn(trainX)\n",
    "    print(\"predicted Train output:\\n\",y_hat)\n",
    "\n",
    "    print(\"TEST input:\\n\",testX)\n",
    "    print(\"Expected output y:\\n\", testy)\n",
    "    \n",
    "    y_hat=NN.forward_nn(testX)\n",
    "    print(\"predicted output:\\n\",y_hat)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.356105,
   "end_time": "2025-03-26T18:48:48.021269",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-26T18:48:43.665164",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
